{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1787ee6a-2874-499d-9eca-ee2128a81690",
   "metadata": {},
   "source": [
    "## **Introduction to NLP**\n",
    "\n",
    "**Natural Language Processing (NLP)** is a field in AI focused on enabling computers to understand, interpret, and generate human language.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Goals**\n",
    "1. **Language Understanding**: Interpreting text/speech for meaning.\n",
    "2. **Language Generation**: Producing human-like language from data.\n",
    "\n",
    "---\n",
    "\n",
    "### **Applications**\n",
    "- **Text Analysis**: Sentiment analysis, classification.\n",
    "- **Translation**: Tools like Google Translate.\n",
    "- **Speech Recognition**: Siri, Alexa.\n",
    "- **Chatbots**: Conversational assistants.\n",
    "- **Information Retrieval**: Search engines, summarization.\n",
    "- **Spam Filtering**: Email filtering.\n",
    "\n",
    "---\n",
    "\n",
    "### **Core Components**\n",
    "- **Syntax**: Sentence structure (e.g., parsing).\n",
    "- **Semantics**: Meaning (e.g., synonyms).\n",
    "- **Pragmatics**: Context and intent (e.g., sarcasm).\n",
    "- **Morphology**: Word forms (roots, affixes).\n",
    "- **Phonetics**: Speech sound processing.\n",
    "\n",
    "---\n",
    "\n",
    "### **Basic Tasks**\n",
    "- **Tokenization**: Splitting text (e.g., \"NLP is fun\" â†’ [\"NLP\", \"is\", \"fun\"]).\n",
    "- **Stopword Removal**: Removing common words.\n",
    "- **Stemming/Lemmatization**: Reducing words to roots.\n",
    "- **POS Tagging**: Grammatical roles (e.g., \"NLP/NN\").\n",
    "- **NER**: Identifying entities (e.g., \"Barack Obama\").\n",
    "- **Dependency Parsing**: Word relationships.\n",
    "- **Sentiment Analysis**: Emotional tone.\n",
    "- **Text Summarization**: Condensed text.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Techniques**\n",
    "- **Bag of Words (BoW)**: Word frequency.\n",
    "- **TF-IDF**: Word importance in context.\n",
    "- **Word Embeddings**: Dense word vectors (e.g., Word2Vec).\n",
    "- **RNNs**: Sequential data models.\n",
    "- **Transformers**: Advanced models like BERT, GPT.\n",
    "\n",
    "---\n",
    "\n",
    "### **Challenges**\n",
    "- **Ambiguity**: Multiple meanings.\n",
    "- **Context Understanding**: Sarcasm, idioms.\n",
    "- **Language Variability**: Dialects, styles.\n",
    "- **Out-of-Vocabulary Words**: Rare/new words.\n",
    "- **Computational Needs**: Processing power.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20442062-ac54-4bba-af97-36c8961da79a",
   "metadata": {},
   "source": [
    "## **NLP Pipeline**\n",
    "\n",
    "An **NLP pipeline** processes raw text into structured data or insights for tasks like sentiment analysis, text classification, or translation.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Stages**\n",
    "\n",
    "1. **Text Acquisition**: Collect text from sources like social media, web scraping, or speech-to-text.\n",
    "2. **Text Preprocessing**:\n",
    "   - **Tokenization**: Split text into words/sentences.\n",
    "   - **Lowercasing**: Convert to lowercase.\n",
    "   - **Stopword Removal**: Remove common words (e.g., \"is,\" \"the\").\n",
    "   - **Stemming/Lemmatization**: Reduce words to root/base forms.\n",
    "   - **Punctuation Removal**: Clean text of symbols and special characters.\n",
    "3. **Text Representation**:\n",
    "   - **Bag of Words (BoW)**: Word frequency vectors.\n",
    "   - **TF-IDF**: Weighted word importance.\n",
    "   - **Embeddings**: Dense representations (e.g., Word2Vec, BERT).\n",
    "4. **Model Training**: Use ML (Naive Bayes, SVM) or DL (RNNs, Transformers).\n",
    "5. **Evaluation**: Metrics like accuracy, F1-score, or BLEU for performance.\n",
    "6. **Post-Processing**: Normalize and format outputs.\n",
    "7. **Deployment**: Use APIs (Flask, FastAPI) or cloud platforms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ce264d-62fe-44c4-b8ba-cd95a8337501",
   "metadata": {},
   "source": [
    "## **Text Processing**\n",
    "\n",
    "Text processing transforms raw text into clean, structured data for NLP tasks. It ensures consistency, reduces noise, and prepares data for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a6ba0a9-d5b7-47f9-b1f1-d6720e145e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import pandas as pd\n",
    "import string,time\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import spacy\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "086d466e-4ae1-4935-8409-17aa09e03546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"IMDB Dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e37e493e-8f64-4d4a-8b8a-6f843838caeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html(data):\n",
    "    pattern = re.compile(\"<.*?>\")\n",
    "    return pattern.sub(r\"\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c154b705-ba1c-4381-8811-12d432d2f9ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. The filming tec...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. The filming tec...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.review = df.review.apply(remove_html)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09625bcf-3fa7-4536-847a-f98a659e7047",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(s):\n",
    "    pattern = re.compile(r\"https?://\\S+|www\\.\\S+\")\n",
    "    return pattern.sub(r\"\", s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01b3e7d3-952c-4308-9ff4-a10f97cc8272",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.review = df.review.apply(remove_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a7167a3-1c33-4827-a734-ec400c2f1e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. The filming tec...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. The filming tec...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "676a542b-8cbe-4800-994b-5b703b1cc018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fb52d64-ac13-4e18-bb01-a8e78fd2a11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30336972-6c72-4999-aaff-2b098c4caaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc(data):\n",
    "    for char in exclude:\n",
    "        data = data.replace(char, \"\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb775c80-c263-4a63-85c1-df222c9a2612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'string With Punctation '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'string. With Punctation? '\n",
    "# print(remove_punc(s))\n",
    "remove_punc(s)\n",
    "\n",
    "## taking high time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da2d5a89-f3b6-4812-9a9c-100ad10a9b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc(s):\n",
    "    return s.translate(str.maketrans(\"\", \"\", exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b9f2fc6-7bad-47ac-9395-081eb5625cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'string With Punctation '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'string. With Punctation? '\n",
    "remove_punc(s)\n",
    "\n",
    "## taking low time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20053f63-6103-4a82-8aac-5fee0ee15819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'certain condition during several generation are modified in the same manner  .'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_text = \"ceertain condition during seveal ggeneration aree moodeified in the same manaer  .\"\n",
    "textBib = TextBlob(incorrect_text)\n",
    "textBib.correct().string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85ac0708-d4f9-4ef2-9d22-83ebe7fed780",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(s):\n",
    "    end_string = []\n",
    "    for word in s.split():\n",
    "        if word not in stopwords.words(\"english\"):\n",
    "            end_string.append(word)\n",
    "    return \" \".join(end_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7781f883-81ee-4547-8ac0-8fc910ef2928",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/mobcoder/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80a74532-beb9-4a9e-8228-72525934e250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.review = df.review.apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c52cdfa-f1de-41fa-9c92-482d46f0360a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello , how are you? \n"
     ]
    }
   ],
   "source": [
    "def remove_emoji(s):\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\"                     \n",
    "        u\"\\U0001F600-\\U0001F64F\"  \n",
    "        u\"\\U0001F300-\\U0001F5FF\"  \n",
    "        u\"\\U0001F680-\\U0001F6FF\"  \n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  \n",
    "        u\"\\U00002700-\\U000027BF\"  \n",
    "        \"]+\", \n",
    "        flags=re.UNICODE\n",
    "    )\n",
    "    return emoji_pattern.sub(r'', s)\n",
    "\n",
    "text_with_emojis = \"Hello ðŸŒŸ, how are you? ðŸš€\"\n",
    "clean_text = remove_emoji(text_with_emojis)\n",
    "print(clean_text)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e44fac4-4c44-40c2-9846-28be94aa968f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 't', 'delhi', '!']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tokenization\n",
    "\n",
    "s1 = \"I am going t delhi !\"\n",
    "word_tokenize(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9119b789-8909-440a-a56d-5cc4273be7a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'do', 'Phd', '.', 'in', 'A.I']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2 = \"I am going to do Phd. in A.I\"\n",
    "word_tokenize(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "479c79ad-30f9-41ca-8294-966f1cca89c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d956db3-e2d5-45af-9ad1-30ff5932af95",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = nlp(s1)\n",
    "doc2 = nlp(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a1f5346e-2931-4b0a-b233-524e99e27246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "I am going t delhi !"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e478e8a-3fbd-4e63-8900-fa8a4c847ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "I am going to do Phd. in A.I"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02ca9e6a-5158-456e-9721-774aa41ed3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Stemming\n",
    "\n",
    "ps = PorterStemmer()\n",
    "def stem_words(s):\n",
    "    return ' '.join([ps.stem(word) for word in s.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e07e4529-d7bc-470b-b724-2ecd5dd8f258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'walk walk walk walk'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"walk walks walking walked\"\n",
    "stem_words(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f1cd10b9-ab59-42d4-a27d-b2e7405ad93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_lemetizer = WordNetLemmatizer()\n",
    "s  = \"He was runing and eating at same time . he was habit of swimmming after playing long hours in the sun\"\n",
    "sentance = nltk.word_tokenize(s)\n",
    "for word in sentance:\n",
    "    if word in exclude:\n",
    "        sentance.remove(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "46202f12-b36d-4006-835e-14302f4c152c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['He',\n",
       " 'was',\n",
       " 'runing',\n",
       " 'and',\n",
       " 'eating',\n",
       " 'at',\n",
       " 'same',\n",
       " 'time',\n",
       " 'he',\n",
       " 'was',\n",
       " 'habit',\n",
       " 'of',\n",
       " 'swimmming',\n",
       " 'after',\n",
       " 'playing',\n",
       " 'long',\n",
       " 'hours',\n",
       " 'in',\n",
       " 'the',\n",
       " 'sun']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e905181-652e-4f7c-b8d7-f889bebf0ff7",
   "metadata": {},
   "source": [
    "## Text Represtation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2b68bb2b-9265-4b4f-853a-6c5c56d487f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>people watch campusx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>campusx watch campusx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>people write comment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>campusx write comment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    text  output\n",
       "0   people watch campusx       1\n",
       "1  campusx watch campusx       1\n",
       "2   people write comment       0\n",
       "3  campusx write comment       0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "df = pd.DataFrame({\n",
    "    'text': ['people watch campusx', 'campusx watch campusx', 'people write comment', 'campusx write comment'],\n",
    "    'output': [1, 1, 0, 0]\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a08e95a8-b61d-4d58-987d-bb17d2f6be0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'people': 2, 'watch': 3, 'campusx': 0, 'write': 4, 'comment': 1}\n"
     ]
    }
   ],
   "source": [
    "# Bay of words\n",
    "bow = cv.fit_transform(df['text'])\n",
    "print(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3e4acfc1-0806-48d4-a573-f947818a9ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 1 1 0]]\n",
      "[[2 0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "print(bow[0].toarray())\n",
    "print(bow[1].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dc202d84-e129-4633-adf7-950beb0ffbed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 1, 0, 1, 1]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.transform([\"campusx watch and write comment of campusx \"]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c0870f0c-daaf-41c6-bcdc-371155f8ed3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#N-gram\n",
    "cv = CountVectorizer(ngram_range= (1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "112301f1-81f7-47e1-8715-246981ef7c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'people': 4, 'watch': 7, 'campusx': 0, 'people watch': 5, 'watch campusx': 8, 'campusx watch': 1, 'write': 9, 'comment': 3, 'people write': 6, 'write comment': 10, 'campusx write': 2}\n"
     ]
    }
   ],
   "source": [
    "bow = cv.fit_transform(df['text'])\n",
    "print(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "36df7c0f-e585-4e88-bbf6-5b310a0a1e30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.49681612, 0.        , 0.61366674, 0.61366674, 0.        ],\n",
       "       [0.8508161 , 0.        , 0.        , 0.52546357, 0.        ],\n",
       "       [0.        , 0.57735027, 0.57735027, 0.        , 0.57735027],\n",
       "       [0.49681612, 0.61366674, 0.        , 0.        , 0.61366674]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tf-Ids\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf.fit_transform(df['text']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "550e063c-7462-45a9-bf89-452d97efd157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.22314355 1.51082562 1.51082562 1.51082562 1.51082562]\n"
     ]
    }
   ],
   "source": [
    "print(tfidf.idf_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420f6f43-0ae7-43ec-b8af-998b88cbfc48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
